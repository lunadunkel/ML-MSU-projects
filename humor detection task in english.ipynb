{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6bcNIdIRGug"
      },
      "source": [
        "# Humor detection (binary classification) на английском языке, используя BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVwFASnvZDBr"
      },
      "source": [
        "Задача распознавания юмора довольно сложная задача для ЛЛМ-ок, в данной работе предпринята попытка улучшения качества распознавания юмора при zero- и few-shot с улучшением RAG подходом.\n",
        "\n",
        "Ссылка на корпус: https://huggingface.co/datasets/CreativeLang/ColBERT_Humor_Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CVQDFlQOLq_"
      },
      "source": [
        "## Zero-shot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlPu4fUiOeXW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelWithLMHead"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CRGI-sEzOIaY",
        "outputId": "43df71f9-205c-449c-b2c8-05a41b102c99"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235,
          "referenced_widgets": [
            "9e2b0dd93626438386f74f7c0d264898",
            "4de66923660549e595113f0e6bb9d511",
            "c941457a2d084e749c640e2e49495362",
            "ea6623e82d474591939f45a690ee0fd0",
            "454fdb8a5cf949ec87a395bdd036ac12",
            "4a4c86a22660481f855c74beae191b3a",
            "62995189f9f646408f97ef1dcda68b5c",
            "487fdd3ed0b34b83b6f042bea954ba3a",
            "1067d78b31ca4adcb83e38f32cfa2a7c",
            "1887a34844a34d3498987ad4be46d2eb",
            "5209bf26fcb94c0194a783beb1e3ecd5",
            "ff7ae8660bf94761837bd428e45aa8dd",
            "0e2f35f996ba4ec9a205246add599cdc",
            "cb0b9eaf94a44597ae8c0e323613fe6e",
            "32ba03aa8e1e43b3a2b2109734a2d9dd",
            "9f07c16f34a847ff8deee852d4cf5ce2",
            "78bf10eecad44a3fa17b4fab7abd6a1e",
            "8f8ce7c79b7747efa3f50aa68fd872a3",
            "87c75eda43654b80a9bd607dcc982847",
            "f314ce1bb3a04811ba4a2b0ea3cf8184",
            "57550a5d605d48eba302d7cb056542bf",
            "59183a85cc364c8a97b8a0822e3a7cba",
            "8c02c836a45a4bc495e599179b5cc7fc",
            "eb9d0030c92f42d48c6ee6e26dae7c6e",
            "aa733d4b3d904876b340717b31211714",
            "a4019266d4fc4ab99b347bfa127a73b5",
            "18238e1ad16840d4a512ff6b2e88adb4",
            "1470c5558bcb4a038ede7034aa16b3a7",
            "9dd3820a47804dddae61ea689cd24a56",
            "c55d83bbbfc8474abf5437b8c49f3a8e",
            "cfde5980e84a405bafbe101d2d8af2bd",
            "327240beb3a940f88e0103fa24b04c16",
            "03ad8edcb7324c6ca93eee789f863448"
          ]
        },
        "collapsed": true,
        "id": "Tz_2YPJ1OANU",
        "outputId": "de422bbd-687e-4ee9-8e12-8b237d232c39"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"CreativeLang/ColBERT_Humor_Detection\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOPH3yZgjpjd"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(data=[ds['train']['text'], ds['train']['humor']], index=['Text', 'Binary']).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "cce5XueVj_K4",
        "outputId": "81373ac1-346c-4f59-cf47-09e4fcc91be2"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nC3emmMVOD9u",
        "outputId": "592fd74b-a48e-4f83-af3e-7be03e1cb92e"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = \"roberta-large\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelWithLMHead.from_pretrained(MODEL_NAME).to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qX6ivUu-ZcoT"
      },
      "outputs": [],
      "source": [
        "pattern_1 = \"Analyze the given text and determine whether it is 'Humorous' or 'Not.' {0}'. Is it humorous? Your response: <mask>.\"\n",
        "pattern_2 = \"Here is a joke: {0}. Is it funny? Your response: <mask>.\"\n",
        "pattern_3 = 'Here is a text: {0}. Say: is it good or bad? Your opinion: <mask>.'\n",
        "\n",
        "pattern_4 = \"I heard a joke: {0}. What's you opinion? Your response: it's <mask> funny.\"\n",
        "\n",
        "pattern_5 = \"I'm writing a comedy show. The joke: {0}. Do you find this joke funny? My friend says it's <mask>.\"\n",
        "pattern_6 = '- Adam, here is a joke: {0}. Is it funny? - Bill, it is <mask>.'\n",
        "pattern_7 = \"- Adam, here is a joke: {0}. Is it funny? - It's really <mask>.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XecjQj5TOQxh"
      },
      "outputs": [],
      "source": [
        "def format_with_pattern(tokenizer, pattern, text):\n",
        "    augmented_text = pattern.format(text).replace(\"<mask>\", tokenizer.mask_token)\n",
        "    tokenization = tokenizer(augmented_text)[\"input_ids\"]\n",
        "    mask_index = tokenization.index(tokenizer.mask_token_id)\n",
        "    return tokenization, mask_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3p4LNDMWkiR"
      },
      "outputs": [],
      "source": [
        "def score_with_model(tokenization, index, device=\"cuda\"):\n",
        "    tensor = torch.LongTensor([tokenization]).to(device)\n",
        "    with torch.no_grad():\n",
        "        model_output = model(tensor)\n",
        "    logits = model_output.logits[0]\n",
        "    log_probs = torch.log_softmax(logits[index], dim=-1)\n",
        "    return log_probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JcPGZ7XKdnWv",
        "outputId": "e191509f-2410-4cf4-ae36-f1a206c4b254"
      },
      "outputs": [],
      "source": [
        "!pip install spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iox6gKHagpg6",
        "outputId": "5473df76-3b26-45b6-f466-db08853c926d"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruykmwY5hTWU"
      },
      "source": [
        "Сравнение косинусной близостм выдаваемых результатов со \"стандартом\" для решения, классифицирует ли модель подаваемые результаты как положительные или нет."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAKpUkEldxFK"
      },
      "outputs": [],
      "source": [
        "def cosine_similarity(input_phrase, add_info=None):\n",
        "    input = nlp(input_phrase)\n",
        "    vector = input.vector\n",
        "    if add_info is None:\n",
        "        standard = ['funny', 'good', 'hilarious', 'amusing', 'beautiful', 'amazing']\n",
        "        not_standard = ['stupid', 'sad', 'bad', 'awful', 'dreary', 'depressing', 'tragic', 'sad', 'disturbing', 'frustrating']\n",
        "    else:\n",
        "        standard = add_info[0]\n",
        "        not_standard = add_info[1]\n",
        "    # standard = ['positive', 'good']\n",
        "    # not_standard = ['negative', 'bad']\n",
        "    standard_vectors = [nlp(phrase).vector for phrase in standard]\n",
        "    not_standard_vectors = [nlp(phrase).vector for phrase in not_standard]\n",
        "    cos_sim_scores = [np.dot(vector, sv) / (np.linalg.norm(vector) * np.linalg.norm(sv)) for sv in standard_vectors]\n",
        "    cos_not_sim_scores = [np.dot(vector, sv) / (np.linalg.norm(vector) * np.linalg.norm(sv)) for sv in not_standard_vectors]\n",
        "    return 1 if np.mean(cos_sim_scores) > np.mean(cos_not_sim_scores) else 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofCwj-EfkGLU"
      },
      "source": [
        "Протестируем способность модели на первых 200 примерах."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vlEu4CFMvoW"
      },
      "source": [
        "Для начала пройдемся по базовым промптам:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "pattern_1 = \"Analyze the given text and determine whether it is 'Humorous' or 'Not.' {0}'. Is it humorous? Your response: <mask>.\"\n",
        "pattern_2 = \"Here is a joke: {0}. Is it funny? Your response: <mask>.\"\n",
        "pattern_3 = 'Here is a text: {0}. Say: is it good or bad? Your opinion: <mask>.'\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbEWa86msStl"
      },
      "outputs": [],
      "source": [
        "corpus, labels = list(df['Text'][:200]), [int(x) for x in df['Binary'][:200]]\n",
        "\n",
        "def basic_prompt_prediction(pattern, corpus, add_info=None):\n",
        "    preds = []\n",
        "    for text, label in zip(corpus, labels):\n",
        "        tokenization, mask_index = format_with_pattern(tokenizer, pattern, text)\n",
        "        log_probs = score_with_model(tokenization, mask_index)\n",
        "        top_probs, top_indexes = torch.topk(log_probs, k=5, dim=-1)\n",
        "        pos_prob, neg_prob = 0, 0\n",
        "        for log_prob, index in zip(top_probs, top_indexes):\n",
        "            probability = np.exp(log_prob.item())\n",
        "            input = tokenizer.decode([index]).replace(' ', '')\n",
        "            if input.lower() in ['no', 'not', 'bad']:\n",
        "                neg_prob += probability\n",
        "            elif input.lower() in ['yes', 'yeah', 'good']:\n",
        "                pos_prob += probability\n",
        "            else:\n",
        "                if cosine_similarity(input.replace(\" \", \"\"), add_info):\n",
        "                    pos_prob += probability\n",
        "                else:\n",
        "                    neg_prob += probability\n",
        "        preds.append(int(pos_prob > neg_prob))\n",
        "    return preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0GxbAdzxMTt"
      },
      "outputs": [],
      "source": [
        "preds_1 = basic_prompt_prediction(pattern_1, corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KR1Vp1aKxVzU"
      },
      "outputs": [],
      "source": [
        "preds_2 = basic_prompt_prediction(pattern_2, corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWDbAq7nxiJr"
      },
      "outputs": [],
      "source": [
        "preds_3 = basic_prompt_prediction(pattern_3, corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frsCNgbOuXky",
        "outputId": "d167bf35-9219-48e1-96e3-11f5ac0eb7b2"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "target_names = ['False', 'True']\n",
        "print(classification_report(labels, preds_1, target_names=target_names, zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "np25oLoyxZNP",
        "outputId": "b249c5ae-366c-4365-8462-17308dd2b6bd"
      },
      "outputs": [],
      "source": [
        "print(classification_report(labels, preds_2, target_names=target_names, zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfgHrmYPxgIS",
        "outputId": "e651acfc-2c3b-4691-b806-66e6b95e401d"
      },
      "outputs": [],
      "source": [
        "print(classification_report(labels, preds_3, target_names=target_names, zero_division=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KhzSXEmuzF9"
      },
      "source": [
        "Как я и предполагала, модель не умеет воспринимать нормально юмор. Она либо все считает несмешным (как в первом пропмте), либо просто некачественно работает.\n",
        "\n",
        "Есть идея попробовать, во-первых, маскировать слово перед funny: она там предскажет либо *not*, либо усиляющий какой-нибудь типа *really*\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "pattern_4 = \"I heard a joke: {0}. What's you opinion? Your response: it's <mask> funny.\"\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SaTfQ9rKjk-z"
      },
      "outputs": [],
      "source": [
        "corpus, labels = list(df['Text'][:200]), [int(x) for x in df['Binary'][0:200]]\n",
        "preds_4 = basic_prompt_prediction(pattern_4, corpus, add_info=[['really', 'rather', 'still', 'even'], ['not', 'no']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adYI1tlU2Z6k",
        "outputId": "d0bea062-3da1-424d-c8ed-980dc9aa302c"
      },
      "outputs": [],
      "source": [
        "print(classification_report(labels, preds_4, target_names=target_names, zero_division=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6METD8X71f3Z"
      },
      "source": [
        "Еще одна идея заключается в более \"живых\" промптах. То есть использовать креативную сторону модели, как бы давая ей диалог, где нужно угадать маскированное слово."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bz2YZz8JMgJS"
      },
      "source": [
        "```\n",
        "pattern_5 = \"I'm writing a comedy show. The joke: {0}. Do you find this joke funny? My friend says it's <mask>.\"\n",
        "pattern_6 = '- Adam, here is a joke: {0}. Is it funny? - Bill, it is <mask>.'\n",
        "pattern_7 = \"- Adam, here is a joke: {0}. Is it funny? - It's really <mask>.\"\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Af9rnHp22VB"
      },
      "outputs": [],
      "source": [
        "corpus, labels = list(df['Text'][:200]), [int(x) for x in df['Binary'][:200]]\n",
        "\n",
        "def advanced_prompt_prediction(pattern, corpus, add_info=None):\n",
        "    preds = []\n",
        "    for text, label in zip(corpus, labels):\n",
        "        tokenization, mask_index = format_with_pattern(tokenizer, pattern, text)\n",
        "        log_probs = score_with_model(tokenization, mask_index)\n",
        "        top_probs, top_indexes = torch.topk(log_probs, k=5, dim=-1)\n",
        "        pos_prob, neg_prob = 0, 0\n",
        "        for log_prob, index in zip(top_probs, top_indexes):\n",
        "            probability = np.exp(log_prob.item())\n",
        "            input = tokenizer.decode([index]).replace(' ', '')\n",
        "            if cosine_similarity(input.replace(\" \", \"\"), add_info):\n",
        "                pos_prob += probability\n",
        "            else:\n",
        "                neg_prob += probability\n",
        "        preds.append(int(pos_prob > neg_prob))\n",
        "    return preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJQzQF9q3DW5"
      },
      "outputs": [],
      "source": [
        "preds_5 = advanced_prompt_prediction(pattern_5, corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8AX3BMK3LHA",
        "outputId": "e4668865-64dd-49b7-8cfb-a0f9993e9192"
      },
      "outputs": [],
      "source": [
        "print(classification_report(labels, preds_5, target_names=target_names, zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXDBy8KP3I1I"
      },
      "outputs": [],
      "source": [
        "preds_6 = advanced_prompt_prediction(pattern_6, corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epxk1RMS3MDG",
        "outputId": "0f8d169c-4282-487f-e9e5-6503238b6fec"
      },
      "outputs": [],
      "source": [
        "print(classification_report(labels, preds_6, target_names=target_names, zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMiHr-mQOfn2"
      },
      "outputs": [],
      "source": [
        "preds_7 = advanced_prompt_prediction(pattern_6, corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXbywhXROkWu",
        "outputId": "b6a46ddb-6da0-4673-9b96-16a4c543d1be"
      },
      "outputs": [],
      "source": [
        "print(classification_report(labels, preds_7, target_names=target_names, zero_division=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5D6ZDkCU37f8"
      },
      "source": [
        "Качество очень случайное, в зависимости от промта у модели bias то в сторону отсутствия юмора, то нет. Но здесь стоит еще проверить более эвристическим методом, возможно, проблема с векторами spacy – зачастую странно высчитывается косинусная близость. Попробуем смотреть по самому вероятному слову, так как промпты подразумевают грамматичность как *not*, так и синонимов *funny*.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jU24OxfK4SZz"
      },
      "outputs": [],
      "source": [
        "def new_advanced_prompt_prediction(pattern, corpus):\n",
        "    preds = []\n",
        "    for text, label in zip(corpus, labels):\n",
        "        tokenization, mask_index = format_with_pattern(tokenizer, pattern, text)\n",
        "        log_probs = score_with_model(tokenization, mask_index)\n",
        "        top_probs, top_indexes = torch.topk(log_probs, k=1, dim=-1)\n",
        "        for log_prob, index in zip(top_probs, top_indexes):\n",
        "            probability = np.exp(log_prob.item())\n",
        "            input = tokenizer.decode([index]).replace(' ', '')\n",
        "            if input == 'not':\n",
        "                pred = 0\n",
        "            elif input in ['funny', 'hilarious', 'amusing', 'humorous', 'comical']:\n",
        "                pred = 1\n",
        "            else:\n",
        "                print(text)\n",
        "                print(input, probability)\n",
        "                print()\n",
        "                pred = cosine_similarity(input.replace(\" \", \"\"))\n",
        "                print(pred)\n",
        "        preds.append(pred)\n",
        "        # preds.append(int(pos_prob > neg_prob))\n",
        "    return preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9IaGQ-XvNiJN"
      },
      "outputs": [],
      "source": [
        "corpus, labels = list(df['Text'][:200]), [int(x) for x in df['Binary'][:200]]\n",
        "preds_5_new = new_advanced_prompt_prediction(pattern_5, corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MI3Uo-IbQNhI",
        "outputId": "183fb90f-5f52-40f6-feeb-3e90971ecd6a"
      },
      "outputs": [],
      "source": [
        "print(classification_report(labels, preds_5_new, target_names=target_names, zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3UmrZfDQQqc"
      },
      "outputs": [],
      "source": [
        "preds_6_new = new_advanced_prompt_prediction(pattern_6, corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsiAHEfcQTIj",
        "outputId": "ddbdc958-e9fa-4004-dac7-3faec720f24f"
      },
      "outputs": [],
      "source": [
        "print(classification_report(labels, preds_6_new, target_names=target_names, zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZ6PnosOQUjI",
        "outputId": "15dc42de-d19f-4003-e5c8-0742c5fe8fd9"
      },
      "outputs": [],
      "source": [
        "preds_7_new = new_advanced_prompt_prediction(pattern_7, corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JQ00wNuQW4J",
        "outputId": "f9397636-0a58-49cc-8366-2ab30441fc47"
      },
      "outputs": [],
      "source": [
        "print(classification_report(labels, preds_7_new, target_names=target_names, zero_division=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDh2_UolQxLK"
      },
      "source": [
        "В итоге получается, что качество все равно скорее случайно, лучше всего работает 5 паттерн\n",
        "\n",
        "`\"I'm writing a comedy show. The joke: {0}. Do you find this joke funny? My friend says it's <mask>.\"`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2z3ZMMQORFNB"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "y_true = labels\n",
        "f_1 = f1_score(labels, preds_1, average='micro')\n",
        "f_2 = f1_score(labels, preds_2, average='micro')\n",
        "f_3 = f1_score(labels, preds_3, average='micro')\n",
        "f_4 = f1_score(labels, preds_4, average='micro')\n",
        "f_5 = f1_score(labels, preds_5_new, average='micro')\n",
        "f_6 = f1_score(labels, preds_6_new, average='micro')\n",
        "f_7 = f1_score(labels, preds_7_new, average='micro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "CSw-GW0LSUYc",
        "outputId": "e1a532a8-0dcb-4fba-ff5b-aa4037db8797"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "x = np.array([\"Pattern 1\", \"Pattern 2\", \"Pattern 3\", \"Pattern 4\", \"Pattern 5\", \"Pattern 6\", \"Pattern 7\"])\n",
        "y = np.array([f_1, f_2, f_3, f_4, f_5, f_6, f_7])\n",
        "\n",
        "ax.bar(x, y)\n",
        "ax.set_title('Результаты на выборке в 200 примеров')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZK1ylK5TFat"
      },
      "outputs": [],
      "source": [
        "preds_1_test, preds_2_test, preds_3_test = [], [], []\n",
        "preds_4_test, preds_5_test, preds_6_test, preds_7_test = [], [], [], []\n",
        "test_corpus, labels = list(df['Text'][199980:]), [int(x) for x in df['Binary'][199980:]]\n",
        "for text in test_corpus:\n",
        "      preds_1_test.extend(basic_prompt_prediction(pattern_1, [text]))\n",
        "      preds_2_test.extend(basic_prompt_prediction(pattern_2, [text]))\n",
        "      preds_3_test.extend(basic_prompt_prediction(pattern_3, [text]))\n",
        "      preds_4_test.extend(basic_prompt_prediction(pattern_4, [text]))\n",
        "      preds_5_test.extend(new_advanced_prompt_prediction(pattern_5, [text]))\n",
        "      preds_6_test.extend(new_advanced_prompt_prediction(pattern_6, [text]))\n",
        "      preds_7_test.extend(new_advanced_prompt_prediction(pattern_7, [text]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXoDOq4KqrDy"
      },
      "outputs": [],
      "source": [
        "y_true = labels\n",
        "f_1 = f1_score(labels, preds_1_test, average='micro')\n",
        "f_2 = f1_score(labels, preds_2_test, average='micro')\n",
        "f_3 = f1_score(labels, preds_3_test, average='micro')\n",
        "f_4 = f1_score(labels, preds_4_test, average='micro')\n",
        "f_5 = f1_score(labels, preds_5_test, average='micro')\n",
        "f_6 = f1_score(labels, preds_6_test, average='micro')\n",
        "f_7 = f1_score(labels, preds_7_test, average='micro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-OLf_nApmsE"
      },
      "outputs": [],
      "source": [
        "results = pd.DataFrame(data=[test_corpus, labels, preds_1_test, preds_2_test, preds_3_test,\n",
        "                             preds_4_test, preds_5_test, preds_6_test, preds_7_test],\n",
        "                       index=['Text', 'True', 1, 2, 3, 4, 5, 6, 7]).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "Tgi1p_ejp0nd",
        "outputId": "c45fa94c-6291-42ce-832e-4861c34473ee"
      },
      "outputs": [],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "pvksMSQgq6bt",
        "outputId": "459357d6-9923-4ee4-c171-b7d21cd03586"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "\n",
        "fruits = ['f_1', 'f_2', 'f_3', 'f_4', 'f_5', 'f_6', 'f_7']\n",
        "counts = [f_1, f_2, f_3, f_4, f_5, f_6, f_7]\n",
        "bar_labels = ['darkgreen', 'lightgreen', '#fdaa48','#6890F0','#A890F0','#fdaa48','#6890F0']\n",
        "bar_colors = ['lightblue', 'lightgreen', 'darkgreen', 'grey', 'lightgrey', 'marn']\n",
        "c = ['#1b9e77', '#a9f971', '#fdaa48','#6890F0','#A890F0','#fdaa48','#6890F0','#A890F0']\n",
        "\n",
        "ax.bar(fruits, counts, label=bar_labels, color=c)\n",
        "\n",
        "# ax.set_ylabel('F-мера')\n",
        "ax.set_title('F-мера')\n",
        "# ax.legend(title='Fruit color')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Uo849QZt44R"
      },
      "source": [
        "## Few-shot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4jU3OZ4t4at"
      },
      "outputs": [],
      "source": [
        "test_prompt = \"\"\"\n",
        "I'm writing a comedy show. Below are some jokes I've already tested:\n",
        "\n",
        "The joke: \"Why don't skeletons fight each other? They don’t have the guts\" It's funny.\n",
        "The joke: \"I told my wife she should embrace her mistakes. She hugged me\" It's funny.\n",
        "The joke: \"Abortion goes front and center in alabama senate race\" It's not funny.\n",
        "\n",
        "New joke: \"{0}\"\n",
        "Is it funny? My friend says it's <mask>.\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOI5qaEzuZWg",
        "outputId": "2cd37903-9c64-424d-ed9e-cbfc150d4034"
      },
      "outputs": [],
      "source": [
        "for text, label in zip(results['Text'], results['True']):\n",
        "    pred = new_advanced_prompt_prediction(test_prompt, [text])\n",
        "    print(f'Text: {text}\\nLabel: {label}\\nPredicted label: {pred[0]}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kM8heyUux3fP"
      },
      "outputs": [],
      "source": [
        "new_prompt = \"\"\"\n",
        "I'm writing a comedy show. Below are some jokes I've already tested:\n",
        "\n",
        "The joke: \"{0}\" It's funny.\n",
        "The joke: \"{1}. She hugged me\" It's funny.\n",
        "The joke: \"{2}\" It's not funny.\n",
        "\n",
        "New joke: \"{3}\"\n",
        "Is it funny? My friend says it's <mask>.\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYyiz51ZOahs"
      },
      "source": [
        "RAG для подбора примеров для промпта"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_KyhdzAi0YEj",
        "outputId": "7623629e-50b7-48a7-c427-8c4a6aeb73fa"
      },
      "outputs": [],
      "source": [
        "!pip install chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "HMJF1jbc2s6K",
        "outputId": "b684d4ba-632e-4aa1-8779-801cd4b4791f"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKz1-yw12rKB"
      },
      "outputs": [],
      "source": [
        "corpus = [str(text) + \". It's \" + ['not funny.', 'funny.'][int(label)] for text, label in zip(df['Text'][201:199980], df['Binary'][201:199980])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0qamq7I-ePM",
        "outputId": "6b1073ba-fc32-4e23-9611-33d4252d7865"
      },
      "outputs": [],
      "source": [
        "bert_model = AutoModelWithLMHead.from_pretrained(MODEL_NAME).to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "collapsed": true,
        "id": "Xzxjtc9s1abD",
        "outputId": "06b5c52a-36d0-4e2a-e14a-b0457fc93739"
      },
      "outputs": [],
      "source": [
        "import chromadb\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "client = chromadb.Client()\n",
        "\n",
        "collection_name = \"corpus_collection\"\n",
        "jokes_collection = client.create_collection(name=collection_name)\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# corpus = [str(text) + ' ' + str(label) for text, label in zip(df['Texts'][201:199980], df['Binary'][201:199980])]\n",
        "\n",
        "for i, text in enumerate(corpus):\n",
        "    embedding = model.encode(text).tolist()\n",
        "    jokes_collection.add(\n",
        "        ids=[f\"text-{i}\"],\n",
        "        documents=[text],\n",
        "        embeddings=[embedding],\n",
        "        metadatas=[{\"text\": text}]\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXAYnqZ-1dWi",
        "outputId": "93ec5c78-a013-445f-d974-170233217013"
      },
      "outputs": [],
      "source": [
        "def retrieve_similar_texts(query, model, collection, top_k=3):\n",
        "    query_embedding = model.encode(query).tolist()\n",
        "\n",
        "    results = collection.query(\n",
        "        query_embeddings=[query_embedding],\n",
        "        n_results=top_k\n",
        "    )\n",
        "\n",
        "    similar_texts = results['documents'][0]\n",
        "    return similar_texts\n",
        "\n",
        "query = \"Mcdonald's will officially kick off all-day breakfast on october 6\"\n",
        "retrieved_texts = retrieve_similar_texts(query, model, jokes_collection)\n",
        "print(retrieved_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtfymarM7qSG"
      },
      "outputs": [],
      "source": [
        "for text, label in zip(results['Text'], results['True']):\n",
        "    print(text)\n",
        "    print(retrieve_similar_texts(text, model, jokes_collection))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOLGcvrSO0uK"
      },
      "source": [
        "Так как лучшее качество было на 5 промпте:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "pattern_5 = \"I'm writing a comedy show. The joke: {0}. Do you find this joke funny? My friend says it's <mask>.\"\n",
        "```\n",
        "\n",
        "Я решила попробовать сначала докрутить его.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0PwhTj21mNd"
      },
      "outputs": [],
      "source": [
        "def create_prompt(text, retrieval):\n",
        "    retrieved_texts = \"\\n\".join(\n",
        "        [f\"The joke: '{joke}'\" for joke in retrieval]\n",
        "    )\n",
        "\n",
        "    prompt = f\"\"\"I'm writing a comedy show. Below are some jokes I've already tested:\n",
        "    {retrieved_texts}\n",
        "\n",
        "    New joke: \"{text}\"\n",
        "    Is it funny? My friend says it's <mask>.\n",
        "    \"\"\"\n",
        "    return prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ygUmmiG-8Z_r",
        "outputId": "25bf6016-8b7d-4eb2-8250-245ef56ef431"
      },
      "outputs": [],
      "source": [
        "for text, label in zip(results['Text'], results['True']):\n",
        "    print(text)\n",
        "    prompt = create_prompt(text, retrieve_similar_texts(text, model, jokes_collection))\n",
        "    print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWAsU0nl-sgM"
      },
      "outputs": [],
      "source": [
        "def score_with_model(tokenization, index, device=\"cuda\"):\n",
        "    tensor = torch.LongTensor([tokenization]).to(device)\n",
        "    with torch.no_grad():\n",
        "        model_output = bert_model(tensor)\n",
        "    logits = model_output.logits[0]\n",
        "    log_probs = torch.log_softmax(logits[index], dim=-1)\n",
        "    return log_probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8EwtcUnH9N5Q"
      },
      "outputs": [],
      "source": [
        "def few_shot_prompt_prediction(prompt):\n",
        "    preds = []\n",
        "    tokenization, mask_index = format_with_pattern(tokenizer, prompt, text)\n",
        "    log_probs = score_with_model(tokenization, mask_index)\n",
        "    top_probs, top_indexes = torch.topk(log_probs, k=1, dim=-1)\n",
        "    for log_prob, index in zip(top_probs, top_indexes):\n",
        "        probability = np.exp(log_prob.item())\n",
        "        input = tokenizer.decode([index]).replace(' ', '')\n",
        "        if input == 'not':\n",
        "            pred = 0\n",
        "        elif input in ['funny', 'hilarious', 'amusing', 'humorous', 'comical']:\n",
        "            pred = 1\n",
        "        else:\n",
        "            print(text)\n",
        "            print(input, probability)\n",
        "            print()\n",
        "            pred = cosine_similarity(input.replace(\" \", \"\"))\n",
        "            print(pred)\n",
        "    preds.append(pred)\n",
        "        # preds.append(int(pos_prob > neg_prob))\n",
        "    return preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OqWHJ0J9yVr",
        "outputId": "9388ac3f-193f-44f5-deac-9ca4ef44509c"
      },
      "outputs": [],
      "source": [
        "for text, label in zip(results['Text'], results['True']):\n",
        "    prompt = create_prompt(text, retrieve_similar_texts(text, model, jokes_collection))\n",
        "    print(text)\n",
        "    print(label, few_shot_prompt_prediction(prompt)[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNbXEDy0_z7y"
      },
      "source": [
        "Однако тут, кажется, и без анализа, если честно, видно, что промпт очень неудачный, потому что происходит сильный перекос в юмор (вероятно из-за количества слова 'funny' в примерах, данных в подводке). Можно попробовать просить модель распределять либо на юмор, либо на журналистику (все тексты что-то типа новостных)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uinpx7mDExNl"
      },
      "source": [
        "Попробуем более классический паттерн.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "Analyze the given text and determine whether it is 'Journalistic'.' Here are some examples. {0}\n",
        "Now classify this one: {1}. The text is <mask>.\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5Cf5esKE-LQ"
      },
      "outputs": [],
      "source": [
        "def create_prompt(prompt, text, retrieval):\n",
        "    retrieved_texts = \"\\n\".join(\n",
        "        [f\"Text: '{retrieved}'\" for retrieved in retrieval]\n",
        "    )\n",
        "\n",
        "    prompt = prompt.format(retrieved_texts, text)\n",
        "    return prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMpWFt8uE1yd"
      },
      "outputs": [],
      "source": [
        "pattern_new = \"\"\"Analyze the given text and determine whether it is 'Journalistic'.' Here are some examples. {0}\n",
        "Now classify this one: {1}. The text is <mask>.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMJ12IqwAXMC"
      },
      "outputs": [],
      "source": [
        "corpus = [str(text) + \" The text is \" + ['jounalistic.', 'humorous.'][int(label)] for text, label in zip(df['Text'][10000:25000], df['Binary'][10000:25000])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LnXvoBBQArls"
      },
      "outputs": [],
      "source": [
        "client = chromadb.Client()\n",
        "\n",
        "collection_name = \"my_collection\"\n",
        "jokes_collection = client.create_collection(name=collection_name)\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "for i, text in enumerate(corpus):\n",
        "    embedding = model.encode(text).tolist()\n",
        "    jokes_collection.add(\n",
        "        ids=[f\"text-{i}\"],\n",
        "        documents=[text],\n",
        "        embeddings=[embedding],\n",
        "        metadatas=[{\"text\": text}]\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTXDjwsHGpG3",
        "outputId": "cb414b43-425f-4423-b158-dfde6cfd05d4"
      },
      "outputs": [],
      "source": [
        "preds_fs = []\n",
        "for text, label in zip(results['Text'], results['True']):\n",
        "    prompt = create_prompt(pattern_new, text, retrieve_similar_texts(text, model, jokes_collection))\n",
        "    tokenization, mask_index = format_with_pattern(tokenizer, prompt, text)\n",
        "    log_probs = score_with_model(tokenization, mask_index)\n",
        "    top_probs, top_indexes = torch.topk(log_probs, k=5, dim=-1)\n",
        "    print(text)\n",
        "    for log_prob, index in zip(top_probs, top_indexes):\n",
        "        word = tokenizer.decode([index]).replace(' ', '')\n",
        "        prob = np.exp(log_prob.item())\n",
        "        # print(word)\n",
        "        if word == 'humorous':\n",
        "            pred = 1\n",
        "            break\n",
        "        elif word == 'journalistic':\n",
        "            pred = 0\n",
        "            break\n",
        "        else:\n",
        "            pred = cosine_similarity(word, add_info=[['humorous'], ['journalistic']])\n",
        "    preds_fs.append(pred)\n",
        "    print(label, pred)\n",
        "    print(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdDvqXDRI0OJ",
        "outputId": "e8dd39c7-b3bc-4ff9-83d9-5811717a53be"
      },
      "outputs": [],
      "source": [
        "y_true = labels\n",
        "f_few = f1_score(labels, preds_fs, average='micro')\n",
        "print(f'Результаты на мини-выборке: {f_few}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "orX6LjCEKNHd"
      },
      "outputs": [],
      "source": [
        "final_corpus, final_labels = list(df['Text'][:200]), [int(x) for x in df['Binary'][:200]]\n",
        "def final_results(final_corpus, pattern_new):\n",
        "    preds_fs = []\n",
        "    for text in final_corpus:\n",
        "        prompt = create_prompt(pattern_new, text, retrieve_similar_texts(text, model, jokes_collection))\n",
        "        tokenization, mask_index = format_with_pattern(tokenizer, prompt, text)\n",
        "        log_probs = score_with_model(tokenization, mask_index)\n",
        "        top_probs, top_indexes = torch.topk(log_probs, k=5, dim=-1)\n",
        "        for log_prob, index in zip(top_probs, top_indexes):\n",
        "            word = tokenizer.decode([index]).replace(' ', '')\n",
        "            prob = np.exp(log_prob.item())\n",
        "            if word == 'humorous':\n",
        "                pred = 1\n",
        "                break\n",
        "            elif word == 'journalistic':\n",
        "                pred = 0\n",
        "                break\n",
        "            else:\n",
        "                pred = cosine_similarity(word, add_info=[['humorous'], ['journalistic']])\n",
        "        preds_fs.append(pred)\n",
        "        # print(label, pred)\n",
        "        # print(\"\")\n",
        "    return preds_fs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rb0JXS3TK3Ag"
      },
      "outputs": [],
      "source": [
        "predictions = final_results(final_corpus, pattern_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W95MqtnCK8N_",
        "outputId": "de4be7cc-f5b3-4d2d-f00c-737dff9af8c7"
      },
      "outputs": [],
      "source": [
        "f_few_final = f1_score(final_labels, predictions, average='micro')\n",
        "print(f'Финальная f-мера на выборке в 200 примеров: {f_few_final}')\n",
        "print()\n",
        "print(classification_report(final_labels, predictions, target_names=target_names, zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZpgNxNkP4nF",
        "outputId": "0f9b4025-1b6e-4d80-a098-058cb24e0853"
      },
      "outputs": [],
      "source": [
        "f_5 = f1_score(final_labels, preds_5_new, average='micro')\n",
        "print(f'Лучшая f-мера на zero-shot: {f_5}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-4jtJEAP-dt"
      },
      "source": [
        "**Выводы:**\n",
        "\n",
        "\n",
        "*   На zero-shot качество было все-таки чуть хуже, чем на few-shot.\n",
        "*   Для задач zero-shot и few-shot пришлось выбирать разные промпты для лучшего качества; для zero-shot приходится немножко сильнее креативить и даже по сути чуток обманывать модель. Для few-shot лучше подходит примитивный промпт, то есть задачу лучше решать как обычную классификацию.\n",
        "*   Сама задача, кажется, довольно сложная для zero-shot, существует много статей о том, что для ЛЛМ очень сложно восприятие юмора.\n",
        "*   Для бинарной классификации по юмору, видимо, не стоит давать модели подводку типа \"юмор vs не-юмор\", так как это сильно перетягивает bias модели в сторону юмора.\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03ad8edcb7324c6ca93eee789f863448": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e2f35f996ba4ec9a205246add599cdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78bf10eecad44a3fa17b4fab7abd6a1e",
            "placeholder": "​",
            "style": "IPY_MODEL_8f8ce7c79b7747efa3f50aa68fd872a3",
            "value": "dataset.csv: 100%"
          }
        },
        "1067d78b31ca4adcb83e38f32cfa2a7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1470c5558bcb4a038ede7034aa16b3a7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18238e1ad16840d4a512ff6b2e88adb4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1887a34844a34d3498987ad4be46d2eb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "327240beb3a940f88e0103fa24b04c16": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32ba03aa8e1e43b3a2b2109734a2d9dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57550a5d605d48eba302d7cb056542bf",
            "placeholder": "​",
            "style": "IPY_MODEL_59183a85cc364c8a97b8a0822e3a7cba",
            "value": " 14.9M/14.9M [00:00&lt;00:00, 81.1MB/s]"
          }
        },
        "454fdb8a5cf949ec87a395bdd036ac12": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "487fdd3ed0b34b83b6f042bea954ba3a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a4c86a22660481f855c74beae191b3a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4de66923660549e595113f0e6bb9d511": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a4c86a22660481f855c74beae191b3a",
            "placeholder": "​",
            "style": "IPY_MODEL_62995189f9f646408f97ef1dcda68b5c",
            "value": "README.md: 100%"
          }
        },
        "5209bf26fcb94c0194a783beb1e3ecd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57550a5d605d48eba302d7cb056542bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59183a85cc364c8a97b8a0822e3a7cba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62995189f9f646408f97ef1dcda68b5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78bf10eecad44a3fa17b4fab7abd6a1e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87c75eda43654b80a9bd607dcc982847": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c02c836a45a4bc495e599179b5cc7fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eb9d0030c92f42d48c6ee6e26dae7c6e",
              "IPY_MODEL_aa733d4b3d904876b340717b31211714",
              "IPY_MODEL_a4019266d4fc4ab99b347bfa127a73b5"
            ],
            "layout": "IPY_MODEL_18238e1ad16840d4a512ff6b2e88adb4"
          }
        },
        "8f8ce7c79b7747efa3f50aa68fd872a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9dd3820a47804dddae61ea689cd24a56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e2b0dd93626438386f74f7c0d264898": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4de66923660549e595113f0e6bb9d511",
              "IPY_MODEL_c941457a2d084e749c640e2e49495362",
              "IPY_MODEL_ea6623e82d474591939f45a690ee0fd0"
            ],
            "layout": "IPY_MODEL_454fdb8a5cf949ec87a395bdd036ac12"
          }
        },
        "9f07c16f34a847ff8deee852d4cf5ce2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4019266d4fc4ab99b347bfa127a73b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_327240beb3a940f88e0103fa24b04c16",
            "placeholder": "​",
            "style": "IPY_MODEL_03ad8edcb7324c6ca93eee789f863448",
            "value": " 200000/200000 [00:00&lt;00:00, 564310.79 examples/s]"
          }
        },
        "aa733d4b3d904876b340717b31211714": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c55d83bbbfc8474abf5437b8c49f3a8e",
            "max": 200000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cfde5980e84a405bafbe101d2d8af2bd",
            "value": 200000
          }
        },
        "c55d83bbbfc8474abf5437b8c49f3a8e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c941457a2d084e749c640e2e49495362": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_487fdd3ed0b34b83b6f042bea954ba3a",
            "max": 1702,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1067d78b31ca4adcb83e38f32cfa2a7c",
            "value": 1702
          }
        },
        "cb0b9eaf94a44597ae8c0e323613fe6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87c75eda43654b80a9bd607dcc982847",
            "max": 14874240,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f314ce1bb3a04811ba4a2b0ea3cf8184",
            "value": 14874240
          }
        },
        "cfde5980e84a405bafbe101d2d8af2bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea6623e82d474591939f45a690ee0fd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1887a34844a34d3498987ad4be46d2eb",
            "placeholder": "​",
            "style": "IPY_MODEL_5209bf26fcb94c0194a783beb1e3ecd5",
            "value": " 1.70k/1.70k [00:00&lt;00:00, 123kB/s]"
          }
        },
        "eb9d0030c92f42d48c6ee6e26dae7c6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1470c5558bcb4a038ede7034aa16b3a7",
            "placeholder": "​",
            "style": "IPY_MODEL_9dd3820a47804dddae61ea689cd24a56",
            "value": "Generating train split: 100%"
          }
        },
        "f314ce1bb3a04811ba4a2b0ea3cf8184": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff7ae8660bf94761837bd428e45aa8dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e2f35f996ba4ec9a205246add599cdc",
              "IPY_MODEL_cb0b9eaf94a44597ae8c0e323613fe6e",
              "IPY_MODEL_32ba03aa8e1e43b3a2b2109734a2d9dd"
            ],
            "layout": "IPY_MODEL_9f07c16f34a847ff8deee852d4cf5ce2"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
